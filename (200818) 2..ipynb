{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>■ 딥러닝 복습</b>\n",
    "    1장. numpy\n",
    "    2장. 퍼셉트론\n",
    "    3장. 3층 신경망 구현\n",
    "    4장. 2층 신경망 구현(수치미분)\n",
    "    5장. 2층 신경망 구현(오차역전파)      tensorflow 1.x -> tensorflow 2.x\n",
    "    --------------------------------------------------------------------\n",
    "    6장. 신경망 학습시키는 기술들\n",
    "    7장. CNN을 이용한 신경망 구현\n",
    "    -------------------------------------------------------------------- 자전거 타는 법\n",
    "\n",
    "    6장. 신경망 학습시키는 기술들\n",
    "        1. 언더피팅 방지하는 방법\n",
    "            - 가중치 초기값 선정\n",
    "                ① Xavier\n",
    "                ② He\n",
    "            - 배치 정규화\n",
    "        2. 오버피팅 방지하는 방법\n",
    "### <b>■ 텐서플로우로 가중치 초기값 선정하는 방법</b>\n",
    "    1. Xavier\n",
    "![fig6-14](fig6-13.png)\n",
    "\n",
    "$$ {{1} \\over {\\sqrt{n}}} \\cdot \\rm{np.random.randn(r,c)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T01:04:03.960180Z",
     "start_time": "2020-08-18T01:03:38.311345Z"
    }
   },
   "outputs": [],
   "source": [
    "W1 = tf.get_variable(name='W1', shape=[784,50], initializer = tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. He 가중치 초기값 구성\n",
    "$$ \\sqrt{{{2} \\over {n}}} \\cdot \\rm{np.random.randn(r,c)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.get_variable(name=\"W1\", shape=[784,50], initializer = tf.contrib.layers.variance_scaling_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제1. 어제 마지막 문제로 만들었던 텐서 플로우로 구현한 신경망 코드에 가중치 초기값을 xavier로 해서 구현하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T01:30:16.839684Z",
     "start_time": "2020-08-18T01:30:01.454704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-a5d4a56c599c>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\knitwill\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\knitwill\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\knitwill\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\knitwill\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\knitwill\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "{1} 에폭 훈련데이터 정확도 :  0.98 \t 테스트 데이터 정확도: 0.92\n",
      "{2} 에폭 훈련데이터 정확도 :  0.98 \t 테스트 데이터 정확도: 0.98\n",
      "{3} 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.99\n",
      "{4} 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.94\n",
      "{5} 에폭 훈련데이터 정확도 :  0.98 \t 테스트 데이터 정확도: 0.97\n",
      "{6} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.99\n",
      "{7} 에폭 훈련데이터 정확도 :  0.96 \t 테스트 데이터 정확도: 0.97\n",
      "{8} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.95\n",
      "{9} 에폭 훈련데이터 정확도 :  0.98 \t 테스트 데이터 정확도: 0.96\n",
      "{10} 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.98\n",
      "{11} 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.95\n",
      "{12} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.96\n",
      "{13} 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.97\n",
      "{14} 에폭 훈련데이터 정확도 :  0.98 \t 테스트 데이터 정확도: 0.95\n",
      "{15} 에폭 훈련데이터 정확도 :  0.98 \t 테스트 데이터 정확도: 0.94\n",
      "{16} 에폭 훈련데이터 정확도 :  0.98 \t 테스트 데이터 정확도: 0.96\n",
      "{17} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.97\n",
      "{18} 에폭 훈련데이터 정확도 :  0.97 \t 테스트 데이터 정확도: 0.97\n",
      "{19} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.99\n",
      "{20} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 은닉1층\n",
    "x = tf.placeholder('float',[None,784])\n",
    "W1 = tf.get_variable(name='W1', shape=[784,50], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.ones([1,50]))\n",
    "\n",
    "y = tf.matmul(x, W1) + b1\n",
    "y_hat = tf.nn.relu(y)\n",
    "\n",
    "# 출력층\n",
    "W2 = tf.get_variable(name='W2', shape=[50,10], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.ones([1,10]))\n",
    "\n",
    "z = tf.matmul(y_hat,W2) + b2\n",
    "z_hat = tf.nn.softmax(z)\n",
    "y_predict = tf.argmax(z_hat, axis=1)\n",
    "\n",
    "# 정확도 확인\n",
    "y_onehot = tf.placeholder('float',[None,10]) # 정답 데이터를 담을 배열\n",
    "y_label = tf.argmax(y_onehot, axis=1)\n",
    "\n",
    "correction_prediction = tf.equal(y_predict, y_label)\n",
    "accuracy = tf.reduce_mean(tf.cast(correction_prediction,'float'))\n",
    "\n",
    "# 오차 확인\n",
    "loss = -tf.reduce_sum(y_onehot * tf.log(z_hat+0.0000001), axis=1)\n",
    "rs = tf.reduce_mean(loss)\n",
    "\n",
    "# 학습\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 변수 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 그래프 실행\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1,601*20):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    batch_x_test, batch_y_test = mnist.test.next_batch(100)\n",
    "    sess.run(train, feed_dict={x:batch_xs, y_onehot:batch_ys})\n",
    "    if not i % 600:\n",
    "        print(i//600,\"에폭 훈련데이터 정확도 : \",sess.run(accuracy, feed_dict={x:batch_xs, y_onehot:batch_ys}),\"\\t\",\"테스트 데이터 정확도:\", sess.run(accuracy, feed_dict={x:batch_x_test, y_onehot:batch_y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※ 문제137. 이번에는 가중치 초기값을 He로 해서 수행하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T01:30:33.997474Z",
     "start_time": "2020-08-18T01:30:18.283304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "{1} 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.96\n",
      "{2} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 1.0\n",
      "{3} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.99\n",
      "{4} 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.99\n",
      "{5} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.97\n",
      "{6} 에폭 훈련데이터 정확도 :  0.97 \t 테스트 데이터 정확도: 0.93\n",
      "{7} 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.98\n",
      "{8} 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.97\n",
      "{9} 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.97\n",
      "{10} 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.98\n",
      "{11} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.97\n",
      "{12} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.98\n",
      "{13} 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.95\n",
      "{14} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.99\n",
      "{15} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.98\n",
      "{16} 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.96\n",
      "{17} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.99\n",
      "{18} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.98\n",
      "{19} 에폭 훈련데이터 정확도 :  0.97 \t 테스트 데이터 정확도: 0.97\n",
      "{20} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.96\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tf.reset_default_graph() # 텐서 그래프 초기화 하는 코드\n",
    "\n",
    "# 은닉1층\n",
    "x = tf.placeholder('float',[None,784])\n",
    "W1 = tf.get_variable(name=\"W1\", shape=[784,50], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b1 = tf.Variable(tf.ones([1,50]))\n",
    "\n",
    "y = tf.matmul(x, W1) + b1\n",
    "y_hat = tf.nn.relu(y)\n",
    "\n",
    "# 출력층\n",
    "W2 = tf.get_variable(name=\"W2\", shape=[50,10], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b2 = tf.Variable(tf.ones([1,10]))\n",
    "\n",
    "z = tf.matmul(y_hat,W2) + b2\n",
    "z_hat = tf.nn.softmax(z)\n",
    "y_predict = tf.argmax(z_hat, axis=1)\n",
    "\n",
    "# 정확도 확인\n",
    "y_onehot = tf.placeholder('float',[None,10]) # 정답 데이터를 담을 배열\n",
    "y_label = tf.argmax(y_onehot, axis=1)\n",
    "\n",
    "correction_prediction = tf.equal(y_predict, y_label)\n",
    "accuracy = tf.reduce_mean(tf.cast(correction_prediction,'float'))\n",
    "\n",
    "# 오차 확인\n",
    "loss = -tf.reduce_sum(y_onehot * tf.log(z_hat+0.0000001), axis=1)\n",
    "rs = tf.reduce_mean(loss)\n",
    "\n",
    "# 학습\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 변수 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 그래프 실행\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1,601*20):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    batch_x_test, batch_y_test = mnist.test.next_batch(100)\n",
    "    sess.run(train, feed_dict={x:batch_xs, y_onehot:batch_ys})\n",
    "    if not i % 600:\n",
    "        print(i//600,\"에폭 훈련데이터 정확도 : \",sess.run(accuracy, feed_dict={x:batch_xs, y_onehot:batch_ys}),\"\\t\",\"테스트 데이터 정확도:\", sess.run(accuracy, feed_dict={x:batch_x_test, y_onehot:batch_y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※ 문제138. 위의 2층 신경망을 3층 신경망으로 변경하시오\n",
    "    기존층 : 입력층 -------> 은닉1층 ------> 출력층\n",
    "             784             100             10\n",
    "    변경후 : 입력층 -------> 은닉1층 ------> 은닉2층 -------> 출력층\n",
    "             784             100             50              10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T01:31:26.072349Z",
     "start_time": "2020-08-18T01:31:05.755894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "{1} 에폭 훈련데이터 정확도 :  0.91 \t 테스트 데이터 정확도: 0.95\n",
      "{2} 에폭 훈련데이터 정확도 :  0.98 \t 테스트 데이터 정확도: 0.97\n",
      "{3} 에폭 훈련데이터 정확도 :  0.97 \t 테스트 데이터 정확도: 0.98\n",
      "{4} 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.93\n",
      "{5} 에폭 훈련데이터 정확도 :  0.97 \t 테스트 데이터 정확도: 0.97\n",
      "{6} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.96\n",
      "{7} 에폭 훈련데이터 정확도 :  0.97 \t 테스트 데이터 정확도: 0.96\n",
      "{8} 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.96\n",
      "{9} 에폭 훈련데이터 정확도 :  0.98 \t 테스트 데이터 정확도: 0.96\n",
      "{10} 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.97\n",
      "{11} 에폭 훈련데이터 정확도 :  0.98 \t 테스트 데이터 정확도: 0.97\n",
      "{12} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.98\n",
      "{13} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.97\n",
      "{14} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.97\n",
      "{15} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.94\n",
      "{16} 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.93\n",
      "{17} 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.98\n",
      "{18} 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.98\n",
      "{19} 에폭 훈련데이터 정확도 :  0.98 \t 테스트 데이터 정확도: 0.96\n",
      "{20} 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.99\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "tf.reset_default_graph() # 텐서 그래프 초기화 하는 코드\n",
    "\n",
    "# 은닉1층\n",
    "x = tf.placeholder('float',[None,784])\n",
    "W1 = tf.get_variable(name=\"W1\", shape=[784,100], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b1 = tf.Variable(tf.ones([1,100]))\n",
    "\n",
    "y = tf.matmul(x, W1) + b1\n",
    "y_hat = tf.nn.relu(y)\n",
    "\n",
    "# 은닉2층\n",
    "W2 = tf.get_variable(name=\"W2\", shape=[100,50], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b2 = tf.Variable(tf.ones([1,50]))\n",
    "\n",
    "y2 = tf.matmul(y_hat,W2) + b2\n",
    "y2_hat = tf.nn.relu(y2)\n",
    "\n",
    "# 출력층\n",
    "W3 = tf.get_variable(name=\"W3\", shape=[50,10], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b3 = tf.Variable(tf.ones([1,10]))\n",
    "\n",
    "z = tf.matmul(y2_hat,W3) + b3\n",
    "z_hat = tf.nn.softmax(z)\n",
    "y_predict = tf.argmax(z_hat, axis=1)\n",
    "\n",
    "# 정확도 확인\n",
    "y_onehot = tf.placeholder('float',[None,10]) # 정답 데이터를 담을 배열\n",
    "y_label = tf.argmax(y_onehot, axis=1)\n",
    "\n",
    "correction_prediction = tf.equal(y_predict, y_label)\n",
    "accuracy = tf.reduce_mean(tf.cast(correction_prediction,'float'))\n",
    "\n",
    "# 오차 확인\n",
    "loss = -tf.reduce_sum(y_onehot * tf.log(z_hat+0.0000001), axis=1)\n",
    "rs = tf.reduce_mean(loss)\n",
    "\n",
    "# 학습\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 변수 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 그래프 실행\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1,601*20):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    batch_x_test, batch_y_test = mnist.test.next_batch(100)\n",
    "    sess.run(train, feed_dict={x:batch_xs, y_onehot:batch_ys})\n",
    "    if not i % 600:\n",
    "        print(i//600,\"에폭 훈련데이터 정확도 : \",sess.run(accuracy, feed_dict={x:batch_xs, y_onehot:batch_ys}),\"\\t\",\"테스트 데이터 정확도:\", sess.run(accuracy, feed_dict={x:batch_x_test, y_onehot:batch_y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>■ 텐서 플로우로 배치 정규화 구현하는 방법</b>\n",
    "    배치 정규화 - 신경망 학습시 가중치 값의 데이터가 골고루 분산될 수 있도록 강제화 하는 장치\n",
    "        층이 깊어져도 가중치의 정규분포를 계속 유지할 수 있도록 층마다 강제화 하는 장치\n",
    "    \n",
    "```python\n",
    "batch_z1 = tf.contrib.layers.batch_norm(z1, True)\n",
    "```\n",
    "    Affine1 ------> 배치 정규화 ------> ReLU\n",
    "     (z1)\n",
    "     \n",
    "#### 예제1. 지금까지 완성한 신경망에 배치 정규화를 은닉 1층에 구현하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T02:07:43.268902Z",
     "start_time": "2020-08-18T02:07:01.848674Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "1 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.97\n",
      "2 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.98\n",
      "3 에폭 훈련데이터 정확도 :  0.98 \t 테스트 데이터 정확도: 0.98\n",
      "4 에폭 훈련데이터 정확도 :  0.96 \t 테스트 데이터 정확도: 0.98\n",
      "5 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.99\n",
      "6 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.97\n",
      "7 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.94\n",
      "8 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.94\n",
      "9 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.99\n",
      "10 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.97\n",
      "11 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.98\n",
      "12 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.98\n",
      "13 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.93\n",
      "14 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.98\n",
      "15 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.95\n",
      "16 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 1.0\n",
      "17 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.99\n",
      "18 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.98\n",
      "19 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 1.0\n",
      "20 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.97\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "tf.reset_default_graph() # 텐서 그래프 초기화 하는 코드\n",
    "\n",
    "# 은닉1층\n",
    "x = tf.placeholder('float',[None,784])\n",
    "W1 = tf.get_variable(name=\"W1\", shape=[784,100], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b1 = tf.Variable(tf.ones([1,100]))\n",
    "\n",
    "y1 = tf.matmul(x, W1) + b1\n",
    "\n",
    "batch_y1 = tf.contrib.layers.batch_norm(y1, True)\n",
    "\n",
    "y1_hat = tf.nn.relu(batch_y1)\n",
    "\n",
    "# 은닉2층\n",
    "W2 = tf.get_variable(name=\"W2\", shape=[100,50], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b2 = tf.Variable(tf.ones([1,50]))\n",
    "\n",
    "y2 = tf.matmul(y1_hat,W2) + b2\n",
    "y2_hat = tf.nn.relu(y2)\n",
    "\n",
    "# 출력층\n",
    "W3 = tf.get_variable(name=\"W3\", shape=[50,10], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b3 = tf.Variable(tf.ones([1,10]))\n",
    "\n",
    "z = tf.matmul(y2_hat,W3) + b3\n",
    "z_hat = tf.nn.softmax(z)\n",
    "y_predict = tf.argmax(z_hat, axis=1)\n",
    "\n",
    "# 정확도 확인\n",
    "y_onehot = tf.placeholder('float',[None,10]) # 정답 데이터를 담을 배열\n",
    "y_label = tf.argmax(y_onehot, axis=1)\n",
    "\n",
    "correction_prediction = tf.equal(y_predict, y_label)\n",
    "accuracy = tf.reduce_mean(tf.cast(correction_prediction,'float'))\n",
    "\n",
    "# 오차 확인\n",
    "loss = -tf.reduce_sum(y_onehot * tf.log(z_hat+0.0000001), axis=1)\n",
    "rs = tf.reduce_mean(loss)\n",
    "\n",
    "# 학습\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 변수 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 그래프 실행\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1,601*20):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    batch_x_test, batch_y_test = mnist.test.next_batch(100)\n",
    "    sess.run(train, feed_dict={x:batch_xs, y_onehot:batch_ys})\n",
    "    if not i % 600:\n",
    "        print(i//600,\"에폭 훈련데이터 정확도 : \",sess.run(accuracy, feed_dict={x:batch_xs, y_onehot:batch_ys}),\"\\t\",\"테스트 데이터 정확도:\", sess.run(accuracy, feed_dict={x:batch_x_test, y_onehot:batch_y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※ 문제139. 은닉 2층에도 배치 정규화를 적용하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T02:10:48.502770Z",
     "start_time": "2020-08-18T02:09:57.254672Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "1 에폭 훈련데이터 정확도 :  0.98 \t 테스트 데이터 정확도: 0.99\n",
      "2 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 0.96\n",
      "3 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.95\n",
      "4 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.98\n",
      "5 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.97\n",
      "6 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.97\n",
      "7 에폭 훈련데이터 정확도 :  0.98 \t 테스트 데이터 정확도: 0.97\n",
      "8 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.98\n",
      "9 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.99\n",
      "10 에폭 훈련데이터 정확도 :  0.98 \t 테스트 데이터 정확도: 0.97\n",
      "11 에폭 훈련데이터 정확도 :  0.99 \t 테스트 데이터 정확도: 1.0\n",
      "12 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.98\n",
      "13 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.97\n",
      "14 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.98\n",
      "15 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 1.0\n",
      "16 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.98\n",
      "17 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.97\n",
      "18 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.97\n",
      "19 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.97\n",
      "20 에폭 훈련데이터 정확도 :  1.0 \t 테스트 데이터 정확도: 0.97\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "tf.reset_default_graph() # 텐서 그래프 초기화 하는 코드\n",
    "\n",
    "# 은닉1층\n",
    "x = tf.placeholder('float',[None,784])\n",
    "W1 = tf.get_variable(name=\"W1\", shape=[784,100], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b1 = tf.Variable(tf.ones([1,100]))\n",
    "\n",
    "y1 = tf.matmul(x, W1) + b1\n",
    "\n",
    "batch_y1 = tf.contrib.layers.batch_norm(y1, True)\n",
    "\n",
    "y1_hat = tf.nn.relu(batch_y1)\n",
    "\n",
    "# 은닉2층\n",
    "W2 = tf.get_variable(name=\"W2\", shape=[100,50], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b2 = tf.Variable(tf.ones([1,50]))\n",
    "\n",
    "y2 = tf.matmul(y1_hat,W2) + b2\n",
    "\n",
    "batch_y2 = tf.contrib.layers.batch_norm(y2, True)\n",
    "\n",
    "y2_hat = tf.nn.relu(batch_y2)\n",
    "\n",
    "# 출력층\n",
    "W3 = tf.get_variable(name=\"W3\", shape=[50,10], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b3 = tf.Variable(tf.ones([1,10]))\n",
    "\n",
    "z = tf.matmul(y2_hat,W3) + b3\n",
    "z_hat = tf.nn.softmax(z)\n",
    "y_predict = tf.argmax(z_hat, axis=1)\n",
    "\n",
    "# 정확도 확인\n",
    "y_onehot = tf.placeholder('float',[None,10]) # 정답 데이터를 담을 배열\n",
    "y_label = tf.argmax(y_onehot, axis=1)\n",
    "\n",
    "correction_prediction = tf.equal(y_predict, y_label)\n",
    "accuracy = tf.reduce_mean(tf.cast(correction_prediction,'float'))\n",
    "\n",
    "# 오차 확인\n",
    "loss = -tf.reduce_sum(y_onehot * tf.log(z_hat+0.0000001), axis=1)\n",
    "rs = tf.reduce_mean(loss)\n",
    "\n",
    "# 학습\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 변수 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 그래프 실행\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1,601*20):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    batch_x_test, batch_y_test = mnist.test.next_batch(100)\n",
    "    sess.run(train, feed_dict={x:batch_xs, y_onehot:batch_ys})\n",
    "    if not i % 600:\n",
    "        print(i//600,\"에폭 훈련데이터 정확도 : \",sess.run(accuracy, feed_dict={x:batch_xs, y_onehot:batch_ys}),\"\\t\",\"테스트 데이터 정확도:\", sess.run(accuracy, feed_dict={x:batch_x_test, y_onehot:batch_y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "tf.reset_default_graph() # 텐서 그래프 초기화 하는 코드\n",
    "\n",
    "# 입력층\n",
    "x = tf.placeholder('float',[None,784])\n",
    "x1 = tf.reshape(x,[-1,28,28,1]) # 흑백사진, 1층, batch 개수를 모르므로 -1. 2차원 -> 4차원으로 변경\n",
    "\n",
    "# Convolution 1층\n",
    "W1 = tf.Variable(tf.random_normal([5,5,1,32], stddev=0.01)) # 필터 32개 생성\n",
    "b1 = tf.Variable(tf.ones([32])) # 숫자 1로 채워진 bias 생성\n",
    "y1 = tf.nn.conv2d(x1, W1, strides=[1,1,1,1], padding='SAME')\n",
    "y1 = y1 + b1\n",
    "y1 = tf.nn.relu(y1)\n",
    "y1 = tf.nn.max_pool(y1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME') # ksize : 필터 사이즈\n",
    "y1 = tf.reshape(y1, [-1,14*14*32]) # y1 4차원 -> 2차원\n",
    "\n",
    "# 완전연결계층 1층 (2층)\n",
    "W2 = tf.get_variable(name=\"W2\", shape=[14*14*32,100], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b2 = tf.Variable(tf.ones([1,100]))\n",
    "\n",
    "y2 = tf.matmul(y1, W2) + b2\n",
    "\n",
    "batch_y2 = tf.contrib.layers.batch_norm(y2, True)\n",
    "\n",
    "y2_hat = tf.nn.relu(batch_y2)\n",
    "\n",
    "# 완전연결계층 2층 (3층)\n",
    "W3 = tf.get_variable(name=\"W3\", shape=[100,50], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b3 = tf.Variable(tf.ones([1,50]))\n",
    "\n",
    "y3 = tf.matmul(y2_hat, W3) + b3\n",
    "\n",
    "batch_y3 = tf.contrib.layers.batch_norm(y3, True)\n",
    "\n",
    "y3_hat = tf.nn.relu(batch_y3)\n",
    "\n",
    "# 출력층 (4층)\n",
    "W4 = tf.get_variable(name=\"W4\", shape=[50,10], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b4 = tf.Variable(tf.ones([1,10]))\n",
    "\n",
    "z = tf.matmul(y3_hat,W4) + b4\n",
    "z_hat = tf.nn.softmax(z)\n",
    "y_predict = tf.argmax(z_hat, axis=1)\n",
    "\n",
    "# 정확도 확인\n",
    "y_onehot = tf.placeholder('float',[None,10]) # 정답 데이터를 담을 배열\n",
    "y_label = tf.argmax(y_onehot, axis=1)\n",
    "\n",
    "correction_prediction = tf.equal(y_predict, y_label)\n",
    "accuracy = tf.reduce_mean(tf.cast(correction_prediction,'float'))\n",
    "\n",
    "# 오차 확인\n",
    "loss = -tf.reduce_sum(y_onehot * tf.log(z_hat+0.0000001), axis=1)\n",
    "rs = tf.reduce_mean(loss)\n",
    "\n",
    "# 학습\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 변수 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 그래프 실행\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1,601*20):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    batch_x_test, batch_y_test = mnist.test.next_batch(100)\n",
    "    sess.run(train, feed_dict={x:batch_xs, y_onehot:batch_ys})\n",
    "    if not i % 600:\n",
    "        print(i//600,\"에폭 훈련데이터 정확도 : \",sess.run(accuracy, feed_dict={x:batch_xs, y_onehot:batch_ys}),\"\\t\",\"테스트 데이터 정확도:\", sess.run(accuracy, feed_dict={x:batch_x_test, y_onehot:batch_y_test}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>■ 텐서 플로우로 dropout 적용하는 방법</b>\n",
    "    드롭아웃(dropout) 사용해야하는 이유 - 오버피팅 방지\n",
    "    구현 예시\n",
    "```python    \n",
    "keep_prob = tf.placeholder('float')\n",
    "    0.8 -> 전체 뉴런 중 80%만 남기고 20% 랜덤으로 삭제\n",
    "    1.0 -> 모든 뉴런을 그대로 남겨둔다\n",
    "y3_drop = tf.nn.dropout(y3, keep_prob)\n",
    "```\n",
    "    훈련할 때는 뉴런을 삭제하고 테스트 할 때는 뉴런을 삭제하지 않으려고 keep_prob로 남겨둠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "tf.reset_default_graph() # 텐서 그래프 초기화 하는 코드\n",
    "\n",
    "# 입력층\n",
    "x = tf.placeholder('float',[None,784])\n",
    "x1 = tf.reshape(x,[-1,28,28,1]) # 흑백사진, 1층, batch 개수를 모르므로 -1. 2차원 -> 4차원으로 변경\n",
    "\n",
    "# Convolution 1층\n",
    "W1 = tf.Variable(tf.random_normal([5,5,1,32], stddev=0.01)) # 필터 32개 생성\n",
    "b1 = tf.Variable(tf.ones([32])) # 숫자 1로 채워진 bias 생성\n",
    "y1 = tf.nn.conv2d(x1, W1, strides=[1,1,1,1], padding='SAME')\n",
    "y1 = y1 + b1\n",
    "y1 = tf.nn.relu(y1)\n",
    "y1 = tf.nn.max_pool(y1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME') # ksize : 필터 사이즈\n",
    "y1 = tf.reshape(y1, [-1,14*14*32]) # y1 4차원 -> 2차원\n",
    "\n",
    "# 완전연결계층 1층 (2층)\n",
    "W2 = tf.get_variable(name=\"W2\", shape=[14*14*32,100], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b2 = tf.Variable(tf.ones([1,100]))\n",
    "\n",
    "y2 = tf.matmul(y1, W2) + b2\n",
    "\n",
    "batch_y2 = tf.contrib.layers.batch_norm(y2, True)\n",
    "\n",
    "y2_hat = tf.nn.relu(batch_y2)\n",
    "\n",
    "# drop out\n",
    "keep_prob = tf.placeholder('float')\n",
    "y2_hat_drop = tf.nn.dropout(y2_hat, keep_prob)\n",
    "\n",
    "# 완전연결계층 2층 (3층)\n",
    "W3 = tf.get_variable(name=\"W3\", shape=[100,50], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b3 = tf.Variable(tf.ones([1,50]))\n",
    "\n",
    "y3 = tf.matmul(y2_hat_drop, W3) + b3\n",
    "\n",
    "batch_y3 = tf.contrib.layers.batch_norm(y3, True)\n",
    "\n",
    "y3_hat = tf.nn.relu(batch_y3)\n",
    "\n",
    "# 출력층 (4층)\n",
    "W4 = tf.get_variable(name=\"W4\", shape=[50,10], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b4 = tf.Variable(tf.ones([1,10]))\n",
    "\n",
    "z = tf.matmul(y3_hat,W4) + b4\n",
    "z_hat = tf.nn.softmax(z)\n",
    "y_predict = tf.argmax(z_hat, axis=1)\n",
    "\n",
    "# 정확도 확인\n",
    "y_onehot = tf.placeholder('float',[None,10]) # 정답 데이터를 담을 배열\n",
    "y_label = tf.argmax(y_onehot, axis=1)\n",
    "\n",
    "correction_prediction = tf.equal(y_predict, y_label)\n",
    "accuracy = tf.reduce_mean(tf.cast(correction_prediction,'float'))\n",
    "\n",
    "# 오차 확인\n",
    "loss = -tf.reduce_sum(y_onehot * tf.log(z_hat+0.0000001), axis=1)\n",
    "rs = tf.reduce_mean(loss)\n",
    "\n",
    "# 학습\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 변수 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 그래프 실행\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1,601*20):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    batch_x_test, batch_y_test = mnist.test.next_batch(100)\n",
    "    sess.run(train, feed_dict={x:batch_xs, y_onehot:batch_ys})\n",
    "    if not i % 600:\n",
    "        print(i//600,\"에폭 훈련데이터 정확도 : \",sess.run(accuracy, feed_dict={x:batch_xs, y_onehot:batch_ys}),\"\\t\",\"테스트 데이터 정확도:\", sess.run(accuracy, feed_dict={x:batch_x_test, y_onehot:batch_y_test}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:16:47.299476Z",
     "start_time": "2020-08-18T05:10:16.213389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-15-159da87ef0a0>:38: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "훈련 1에폭 정확도 : 0.65\n",
      "테스트 1에폭 정확도 : 0.46\n",
      "-----------------------------------------------\n",
      "훈련 2에폭 정확도 : 0.99\n",
      "테스트 2에폭 정확도 : 0.98\n",
      "-----------------------------------------------\n",
      "훈련 3에폭 정확도 : 0.98\n",
      "테스트 3에폭 정확도 : 0.99\n",
      "-----------------------------------------------\n",
      "훈련 4에폭 정확도 : 1.0\n",
      "테스트 4에폭 정확도 : 0.98\n",
      "-----------------------------------------------\n",
      "훈련 5에폭 정확도 : 0.99\n",
      "테스트 5에폭 정확도 : 1.0\n",
      "-----------------------------------------------\n",
      "훈련 6에폭 정확도 : 0.98\n",
      "테스트 6에폭 정확도 : 0.98\n",
      "-----------------------------------------------\n",
      "훈련 7에폭 정확도 : 1.0\n",
      "테스트 7에폭 정확도 : 1.0\n",
      "-----------------------------------------------\n",
      "훈련 8에폭 정확도 : 0.99\n",
      "테스트 8에폭 정확도 : 0.98\n",
      "-----------------------------------------------\n",
      "훈련 9에폭 정확도 : 1.0\n",
      "테스트 9에폭 정확도 : 0.98\n",
      "-----------------------------------------------\n",
      "훈련 10에폭 정확도 : 1.0\n",
      "테스트 10에폭 정확도 : 1.0\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-159da87ef0a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0mtest_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_onehot\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# 1에폭마다 정확도 확인\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "tf.reset_default_graph() # 텐서 그래프 초기화 하는 코드\n",
    "\n",
    "# 입력층\n",
    "x = tf.placeholder('float',[None,784])\n",
    "x1 = tf.reshape(x,[-1,28,28,1]) # 흑백사진, 1층, batch 개수를 모르므로 -1. 2차원 -> 4차원으로 변경\n",
    "\n",
    "# Convolution 1층\n",
    "W1 = tf.Variable(tf.random_normal([5,5,1,32], stddev=0.01)) # 필터 32개 생성\n",
    "b1 = tf.Variable(tf.ones([32])) # 숫자 1로 채워진 bias 생성\n",
    "y1 = tf.nn.conv2d(x1, W1, strides=[1,1,1,1], padding='SAME')\n",
    "y1 = y1 + b1\n",
    "y1 = tf.nn.relu(y1)\n",
    "y1 = tf.nn.max_pool(y1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME') # ksize : 필터 사이즈\n",
    "y1 = tf.reshape(y1, [-1,14*14*32]) # y1 4차원 -> 2차원\n",
    "\n",
    "# 완전연결계층 1층 (2층)\n",
    "W2 = tf.get_variable(name=\"W2\", shape=[14*14*32,100], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b2 = tf.Variable(tf.ones([1,100]))\n",
    "\n",
    "y2 = tf.matmul(y1, W2) + b2\n",
    "\n",
    "batch_y2 = tf.contrib.layers.batch_norm(y2, True)\n",
    "\n",
    "y2_hat = tf.nn.relu(batch_y2)\n",
    "\n",
    "# drop out\n",
    "keep_prob = tf.placeholder('float')\n",
    "y2_hat_drop = tf.nn.dropout(y2_hat, keep_prob)\n",
    "\n",
    "# 완전연결계층 2층 (3층)\n",
    "W3 = tf.get_variable(name=\"W3\", shape=[100,50], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b3 = tf.Variable(tf.ones([1,50]))\n",
    "\n",
    "y3 = tf.matmul(y2_hat_drop, W3) + b3\n",
    "\n",
    "batch_y3 = tf.contrib.layers.batch_norm(y3, True)\n",
    "\n",
    "y3_hat = tf.nn.relu(batch_y3)\n",
    "\n",
    "# 출력층 (4층)\n",
    "W4 = tf.get_variable(name=\"W4\", shape=[50,10], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b4 = tf.Variable(tf.ones([1,10]))\n",
    "\n",
    "z = tf.matmul(y3_hat,W4) + b4\n",
    "z_hat = tf.nn.softmax(z)\n",
    "y_predict = tf.argmax(z_hat, axis=1)\n",
    "\n",
    "# 정확도 확인\n",
    "y_onehot = tf.placeholder('float',[None,10]) # 정답 데이터를 담을 배열\n",
    "y_label = tf.argmax(y_onehot, axis=1)\n",
    "\n",
    "correction_prediction = tf.equal(y_predict, y_label)\n",
    "accuracy = tf.reduce_mean(tf.cast(correction_prediction,'float'))\n",
    "\n",
    "# 오차 확인\n",
    "loss = -tf.reduce_sum(y_onehot * tf.log(z_hat+0.0000001), axis=1)\n",
    "rs = tf.reduce_mean(loss)\n",
    "\n",
    "# 학습\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 변수 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 그래프 실행\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for j in range(20):\n",
    "        for i in range(600):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "            test_xs, test_ys = mnist.test.next_batch(100)\n",
    "\n",
    "            sess.run(train, feed_dict={x: batch_xs, y_onehot: batch_ys, keep_prob: 0.9})\n",
    "            \n",
    "            if i == 0: # 1에폭마다 정확도 확인\n",
    "                train_acc = sess.run(accuracy, feed_dict={x: batch_xs, y_onehot: batch_ys, keep_prob: 1.0}) # 훈련 데이터의 정확도 \n",
    "                test_acc = sess.run(accuracy, feed_dict={x: test_xs, y_onehot: test_ys, keep_prob: 1.0}) # 테스트 데이터의 정확도\n",
    "\n",
    "                # 그래프용 리스트에 정확도 담기\n",
    "                train_acc_list.append(train_acc) \n",
    "                test_acc_list.append(test_acc)\n",
    "\n",
    "                print('훈련', str(j + 1) + '에폭 정확도 :', train_acc)\n",
    "                print('테스트', str(j + 1) + '에폭 정확도 :', test_acc)\n",
    "                print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>■ 훈련과 테스트 데이터의 정확도가 시각화 될 수 있도록 코드를 추가 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:23:35.759280Z",
     "start_time": "2020-08-18T05:19:03.888046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "훈련 1에폭 정확도 : 0.65\n",
      "테스트 1에폭 정확도 : 0.42\n",
      "-----------------------------------------------\n",
      "훈련 2에폭 정확도 : 0.99\n",
      "테스트 2에폭 정확도 : 0.99\n",
      "-----------------------------------------------\n",
      "훈련 3에폭 정확도 : 1.0\n",
      "테스트 3에폭 정확도 : 0.99\n",
      "-----------------------------------------------\n",
      "훈련 4에폭 정확도 : 1.0\n",
      "테스트 4에폭 정확도 : 1.0\n",
      "-----------------------------------------------\n",
      "훈련 5에폭 정확도 : 1.0\n",
      "테스트 5에폭 정확도 : 1.0\n",
      "-----------------------------------------------\n",
      "훈련 6에폭 정확도 : 1.0\n",
      "테스트 6에폭 정확도 : 0.99\n",
      "-----------------------------------------------\n",
      "훈련 7에폭 정확도 : 0.99\n",
      "테스트 7에폭 정확도 : 1.0\n",
      "-----------------------------------------------\n",
      "훈련 8에폭 정확도 : 0.98\n",
      "테스트 8에폭 정확도 : 0.99\n",
      "-----------------------------------------------\n",
      "훈련 9에폭 정확도 : 1.0\n",
      "테스트 9에폭 정확도 : 1.0\n",
      "-----------------------------------------------\n",
      "훈련 10에폭 정확도 : 1.0\n",
      "테스트 10에폭 정확도 : 0.99\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "tf.reset_default_graph() # 텐서 그래프 초기화 하는 코드\n",
    "\n",
    "# 입력층\n",
    "x = tf.placeholder('float',[None,784])\n",
    "x1 = tf.reshape(x,[-1,28,28,1]) # 흑백사진, 1층, batch 개수를 모르므로 -1. 2차원 -> 4차원으로 변경\n",
    "\n",
    "# Convolution 1층\n",
    "W1 = tf.Variable(tf.random_normal([5,5,1,32], stddev=0.01)) # 필터 32개 생성\n",
    "b1 = tf.Variable(tf.ones([32])) # 숫자 1로 채워진 bias 생성\n",
    "y1 = tf.nn.conv2d(x1, W1, strides=[1,1,1,1], padding='SAME')\n",
    "y1 = y1 + b1\n",
    "y1 = tf.nn.relu(y1)\n",
    "y1 = tf.nn.max_pool(y1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME') # ksize : 필터 사이즈\n",
    "y1 = tf.reshape(y1, [-1,14*14*32]) # y1 4차원 -> 2차원\n",
    "\n",
    "# 완전연결계층 1층 (2층)\n",
    "W2 = tf.get_variable(name=\"W2\", shape=[14*14*32,100], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b2 = tf.Variable(tf.ones([1,100]))\n",
    "\n",
    "y2 = tf.matmul(y1, W2) + b2\n",
    "\n",
    "batch_y2 = tf.contrib.layers.batch_norm(y2, True)\n",
    "\n",
    "y2_hat = tf.nn.relu(batch_y2)\n",
    "\n",
    "# drop out\n",
    "keep_prob = tf.placeholder('float')\n",
    "y2_hat_drop = tf.nn.dropout(y2_hat, keep_prob)\n",
    "\n",
    "# 완전연결계층 2층 (3층)\n",
    "W3 = tf.get_variable(name=\"W3\", shape=[100,50], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b3 = tf.Variable(tf.ones([1,50]))\n",
    "\n",
    "y3 = tf.matmul(y2_hat_drop, W3) + b3\n",
    "\n",
    "batch_y3 = tf.contrib.layers.batch_norm(y3, True)\n",
    "\n",
    "y3_hat = tf.nn.relu(batch_y3)\n",
    "\n",
    "# 출력층 (4층)\n",
    "W4 = tf.get_variable(name=\"W4\", shape=[50,10], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b4 = tf.Variable(tf.ones([1,10]))\n",
    "\n",
    "z = tf.matmul(y3_hat,W4) + b4\n",
    "z_hat = tf.nn.softmax(z)\n",
    "y_predict = tf.argmax(z_hat, axis=1)\n",
    "\n",
    "# 정확도 확인\n",
    "y_onehot = tf.placeholder('float',[None,10]) # 정답 데이터를 담을 배열\n",
    "y_label = tf.argmax(y_onehot, axis=1)\n",
    "\n",
    "correction_prediction = tf.equal(y_predict, y_label)\n",
    "accuracy = tf.reduce_mean(tf.cast(correction_prediction,'float'))\n",
    "\n",
    "# 오차 확인\n",
    "loss = -tf.reduce_sum(y_onehot * tf.log(z_hat+0.0000001), axis=1)\n",
    "rs = tf.reduce_mean(loss)\n",
    "\n",
    "# 학습\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 변수 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 그래프 실행\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for j in range(10):\n",
    "        for i in range(600):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "            test_xs, test_ys = mnist.test.next_batch(100)\n",
    "\n",
    "            sess.run(train, feed_dict={x: batch_xs, y_onehot: batch_ys, keep_prob: 0.9})\n",
    "            \n",
    "            if i == 0: # 1에폭마다 정확도 확인\n",
    "                train_acc = sess.run(accuracy, feed_dict={x: batch_xs, y_onehot: batch_ys, keep_prob: 1.0}) # 훈련 데이터의 정확도 \n",
    "                test_acc = sess.run(accuracy, feed_dict={x: test_xs, y_onehot: test_ys, keep_prob: 1.0}) # 테스트 데이터의 정확도\n",
    "\n",
    "                # 그래프용 리스트에 정확도 담기\n",
    "                train_acc_list.append(train_acc) \n",
    "                test_acc_list.append(test_acc)\n",
    "\n",
    "                print('훈련', str(j + 1) + '에폭 정확도 :', train_acc)\n",
    "                print('테스트', str(j + 1) + '에폭 정확도 :', test_acc)\n",
    "                print('-----------------------------------------------')\n",
    "                \n",
    "# 그래프 작성\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (20,10)\n",
    "plt.rcParams.update({'font.size':20})\n",
    "\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "\n",
    "plt.plot()\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(min(min(train_acc_list),min(test_acc_list))-0.1, 1.005)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※ 문제140. 위의 CNN 신경망을 아래와 같이 구현하시오\n",
    "    변경 전 : 입력층 ----> Conv1 ----> pooling ----> FC1층 ----> FC2층 ----> 출력층\n",
    "              784          32                        100         50          10\n",
    "    변경 후 : 입력층 ----> Conv1 ----> pooling ----> Conv2 ----> pooling ----> FC1층 ----> FC2층 ----> 출력층\n",
    "              784          32                         64                       100         50          10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:56:08.466616Z",
     "start_time": "2020-08-18T05:43:31.194762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "훈련 1에폭 정확도 : 0.5\n",
      "테스트 1에폭 정확도 : 0.21\n",
      "-----------------------------------------------\n",
      "훈련 2에폭 정확도 : 1.0\n",
      "테스트 2에폭 정확도 : 0.98\n",
      "-----------------------------------------------\n",
      "훈련 3에폭 정확도 : 0.99\n",
      "테스트 3에폭 정확도 : 1.0\n",
      "-----------------------------------------------\n",
      "훈련 4에폭 정확도 : 0.99\n",
      "테스트 4에폭 정확도 : 0.98\n",
      "-----------------------------------------------\n",
      "훈련 5에폭 정확도 : 0.99\n",
      "테스트 5에폭 정확도 : 0.98\n",
      "-----------------------------------------------\n",
      "훈련 6에폭 정확도 : 0.99\n",
      "테스트 6에폭 정확도 : 0.97\n",
      "-----------------------------------------------\n",
      "훈련 7에폭 정확도 : 0.99\n",
      "테스트 7에폭 정확도 : 1.0\n",
      "-----------------------------------------------\n",
      "훈련 8에폭 정확도 : 1.0\n",
      "테스트 8에폭 정확도 : 0.99\n",
      "-----------------------------------------------\n",
      "훈련 9에폭 정확도 : 1.0\n",
      "테스트 9에폭 정확도 : 1.0\n",
      "-----------------------------------------------\n",
      "훈련 10에폭 정확도 : 1.0\n",
      "테스트 10에폭 정확도 : 0.98\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "tf.reset_default_graph() # 텐서 그래프 초기화 하는 코드\n",
    "\n",
    "# 입력층\n",
    "x = tf.placeholder('float',[None,784])\n",
    "x1 = tf.reshape(x,[-1,28,28,1]) # 흑백사진, 1층, batch 개수를 모르므로 -1. 2차원 -> 4차원으로 변경\n",
    "\n",
    "# Convolution 1층\n",
    "W1 = tf.Variable(tf.random_normal([5,5,1,32], stddev=0.01)) # 필터 32개 생성\n",
    "b1 = tf.Variable(tf.ones([32])) # 숫자 1로 채워진 bias 생성\n",
    "y1 = tf.nn.conv2d(x1, W1, strides=[1,1,1,1], padding='SAME') + b1\n",
    "y1 = tf.nn.relu(y1)\n",
    "y1 = tf.nn.max_pool(y1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME') # ksize : 필터 사이즈\n",
    "# y1 = tf.reshape(y1, [-1,14*14*32]) # y1 4차원 -> 2차원\n",
    "\n",
    "# Convolution 2층\n",
    "W2 = tf.Variable(tf.random_normal([5,5,32,64], stddev=0.01)) \n",
    "b2 = tf.Variable(tf.ones([64])) # 숫자 1로 채워진 bias 생성\n",
    "y2 = tf.nn.conv2d(y1, W2, strides=[1,1,1,1], padding='SAME') + b2\n",
    "y2 = tf.nn.relu(y2)\n",
    "y2 = tf.nn.max_pool(y2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME') \n",
    "y2 = tf.reshape(y2, [-1,7*7*64]) # y1 4차원 -> 2차원\n",
    "\n",
    "# 완전연결계층 1층 (2층)\n",
    "W3 = tf.get_variable(name=\"W3\", shape=[7*7*64,100], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b3 = tf.Variable(tf.ones([1,100]))\n",
    "\n",
    "y3 = tf.matmul(y2, W3) + b3\n",
    "\n",
    "batch_y2 = tf.contrib.layers.batch_norm(y3, True)\n",
    "\n",
    "y2_hat = tf.nn.relu(batch_y2)\n",
    "\n",
    "# drop out\n",
    "keep_prob = tf.placeholder('float')\n",
    "y2_hat_drop = tf.nn.dropout(y2_hat, keep_prob)\n",
    "\n",
    "# 완전연결계층 2층 (3층)\n",
    "W4 = tf.get_variable(name=\"W4\", shape=[100,50], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b4 = tf.Variable(tf.ones([1,50]))\n",
    "\n",
    "y4 = tf.matmul(y2_hat_drop, W4) + b4\n",
    "\n",
    "batch_y3 = tf.contrib.layers.batch_norm(y4, True)\n",
    "\n",
    "y3_hat = tf.nn.relu(batch_y3)\n",
    "\n",
    "# 출력층 (4층)\n",
    "W5 = tf.get_variable(name=\"W5\", shape=[50,10], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "b5 = tf.Variable(tf.ones([1,10]))\n",
    "\n",
    "z = tf.matmul(y3_hat,W5) + b5\n",
    "z_hat = tf.nn.softmax(z)\n",
    "y_predict = tf.argmax(z_hat, axis=1)\n",
    "\n",
    "# 정확도 확인\n",
    "y_onehot = tf.placeholder('float',[None,10]) # 정답 데이터를 담을 배열\n",
    "y_label = tf.argmax(y_onehot, axis=1)\n",
    "\n",
    "correction_prediction = tf.equal(y_predict, y_label)\n",
    "accuracy = tf.reduce_mean(tf.cast(correction_prediction,'float'))\n",
    "\n",
    "# 오차 확인\n",
    "loss = -tf.reduce_sum(y_onehot * tf.log(z_hat+0.0000001), axis=1)\n",
    "rs = tf.reduce_mean(loss)\n",
    "\n",
    "# 학습\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 변수 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 그래프 실행\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for j in range(10):\n",
    "        for i in range(600):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "            test_xs, test_ys = mnist.test.next_batch(100)\n",
    "\n",
    "            sess.run(train, feed_dict={x: batch_xs, y_onehot: batch_ys, keep_prob: 0.9})\n",
    "            \n",
    "            if i == 0: # 1에폭마다 정확도 확인\n",
    "                train_acc = sess.run(accuracy, feed_dict={x: batch_xs, y_onehot: batch_ys, keep_prob: 1.0}) # 훈련 데이터의 정확도 \n",
    "                test_acc = sess.run(accuracy, feed_dict={x: test_xs, y_onehot: test_ys, keep_prob: 1.0}) # 테스트 데이터의 정확도\n",
    "\n",
    "                # 그래프용 리스트에 정확도 담기\n",
    "                train_acc_list.append(train_acc) \n",
    "                test_acc_list.append(test_acc)\n",
    "\n",
    "                print('훈련', str(j + 1) + '에폭 정확도 :', train_acc)\n",
    "                print('테스트', str(j + 1) + '에폭 정확도 :', test_acc)\n",
    "                print('-----------------------------------------------')\n",
    "                \n",
    "# # 그래프 작성\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.rcParams['figure.figsize'] = (20,10)\n",
    "# plt.rcParams.update({'font.size':20})\n",
    "\n",
    "# markers = {'train': 'o', 'test': 's'}\n",
    "# x = np.arange(len(train_acc_list))\n",
    "\n",
    "# plt.plot()\n",
    "# plt.plot(x, train_acc_list, label='train acc')\n",
    "# plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "# plt.xlabel(\"epochs\")\n",
    "# plt.ylabel(\"accuracy\")\n",
    "# plt.ylim(min(min(train_acc_list),min(test_acc_list))-0.1, 1.005)\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>■ cifar10 데이터를 이용한 신경망 구성</b>\n",
    "    cifar10은 총 6만 개의 데이터 셋으로 이루어져 있으며 그 중 5만 개가 훈련데이터, 1만 개가 테스트 데이터\n",
    "    class는 비행기부터 트럭까지 총 10개\n",
    "        1. 비행기\n",
    "        2. 자동차\n",
    "        3. 새\n",
    "        4. 고양이\n",
    "        5. 사슴\n",
    "        6. 강아지\n",
    "        7. 개구리\n",
    "        8. 말\n",
    "        9. 배\n",
    "        10. 트럭\n",
    "### <b>■ 신경망 구현 홈페이지를 만들려면 필요한 코드</b>\n",
    "    1. 사진 데이터를 신경망에 로드하는 코드들\n",
    "    2. 사진 이미지를 분류하는 신경망 코드 --> 구글\n",
    "    3. 홈페이지 구축하는 코드(RShiny)\n",
    "    \n",
    "### <b>■ 1. 사진 데이터를 신경망에 로드하는 코드들</b>\n",
    "#### 예제1. 사진을 불러와서 아래와 같이 이미지 이름을 출력하는 함수를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T06:40:03.910915Z",
     "start_time": "2020-08-18T06:40:03.903920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.png', '10.png', '100.png', '11.png', '12.png', '13.png', '14.png', '15.png', '16.png', '17.png', '18.png', '19.png', '2.png', '20.png', '21.png', '22.png', '23.png', '24.png', '25.png', '26.png', '27.png', '28.png', '29.png', '3.png', '30.png', '31.png', '32.png', '33.png', '34.png', '35.png', '36.png', '37.png', '38.png', '39.png', '4.png', '40.png', '41.png', '42.png', '43.png', '44.png', '45.png', '46.png', '47.png', '48.png', '49.png', '5.png', '50.png', '51.png', '52.png', '53.png', '54.png', '55.png', '56.png', '57.png', '58.png', '59.png', '6.png', '60.png', '61.png', '62.png', '63.png', '64.png', '65.png', '66.png', '67.png', '68.png', '69.png', '7.png', '70.png', '71.png', '72.png', '73.png', '74.png', '75.png', '76.png', '77.png', '78.png', '79.png', '8.png', '80.png', '81.png', '82.png', '83.png', '84.png', '85.png', '86.png', '87.png', '88.png', '89.png', '9.png', '90.png', '91.png', '92.png', '93.png', '94.png', '95.png', '96.png', '97.png', '98.png', '99.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def image_load(path):\n",
    "    file_list = os.listdir(path)\n",
    "    return file_list\n",
    "\n",
    "\n",
    "train_image = 'd:/tensor/cifar10/train100/'\n",
    "print(image_load(train_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제2. 위의 결과에서 .png는 빼고 숫자만 출력되게 하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T06:43:48.746386Z",
     "start_time": "2020-08-18T06:43:48.739390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '10', '100', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def image_load(path):\n",
    "    file_list = os.listdir(path)\n",
    "    file_name = []\n",
    "    for i in file_list:\n",
    "        name = re.sub('[^0-9]','',i)\n",
    "        file_name.append(name)\n",
    "        \n",
    "    return file_name\n",
    "\n",
    "train_image = 'd:/tensor/cifar10/train100/'\n",
    "print(image_load(train_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제3. 위의 결과를 정렬해서 출력하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T06:50:39.521200Z",
     "start_time": "2020-08-18T06:50:39.514203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "def image_load(path):\n",
    "    file_list = os.listdir(path)\n",
    "    file_name = []\n",
    "    for i in file_list:\n",
    "        file_name.append(int(re.sub('[^0-9]', '', i)))\n",
    "\n",
    "    file_name.sort()\n",
    "\n",
    "    return file_name\n",
    "\n",
    "\n",
    "train_image = 'd:/tensor/cifar10/train100/'\n",
    "print(image_load(train_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제4. 위의 출력된 결과에서 다시 .png를 붙여서 아래와 같이 출력되게 하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T06:52:25.152338Z",
     "start_time": "2020-08-18T06:52:25.145342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.png', '2.png', '3.png', '4.png', '5.png', '6.png', '7.png', '8.png', '9.png', '10.png', '11.png', '12.png', '13.png', '14.png', '15.png', '16.png', '17.png', '18.png', '19.png', '20.png', '21.png', '22.png', '23.png', '24.png', '25.png', '26.png', '27.png', '28.png', '29.png', '30.png', '31.png', '32.png', '33.png', '34.png', '35.png', '36.png', '37.png', '38.png', '39.png', '40.png', '41.png', '42.png', '43.png', '44.png', '45.png', '46.png', '47.png', '48.png', '49.png', '50.png', '51.png', '52.png', '53.png', '54.png', '55.png', '56.png', '57.png', '58.png', '59.png', '60.png', '61.png', '62.png', '63.png', '64.png', '65.png', '66.png', '67.png', '68.png', '69.png', '70.png', '71.png', '72.png', '73.png', '74.png', '75.png', '76.png', '77.png', '78.png', '79.png', '80.png', '81.png', '82.png', '83.png', '84.png', '85.png', '86.png', '87.png', '88.png', '89.png', '90.png', '91.png', '92.png', '93.png', '94.png', '95.png', '96.png', '97.png', '98.png', '99.png', '100.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "def image_load(path):\n",
    "    file_list = os.listdir(path)\n",
    "\n",
    "    file_name = []\n",
    "    for i in file_list:\n",
    "        file_name.append(int(re.sub('[^0-9]', '', i)))\n",
    "\n",
    "    file_name.sort()\n",
    "\n",
    "    file_res = []\n",
    "    for i in file_name:\n",
    "        file_res.append(str(i)+'.png')\n",
    "\n",
    "    return file_res\n",
    "\n",
    "\n",
    "train_image = 'd:/tensor/cifar10/train100/'\n",
    "print(image_load(train_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제5. 이미지 이름 앞에 절대 경로가 아래처럼 붙게 하시오\n",
    "    ['d:/tensor/cifar10/train100/1.png','d:/tensor/cifar10/train100/2.png',...,'d:/tensor/cifar10/train100/100.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T06:56:22.150153Z",
     "start_time": "2020-08-18T06:56:22.142158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d:/tensor/cifar10/train100/1.png', 'd:/tensor/cifar10/train100/2.png', 'd:/tensor/cifar10/train100/3.png', 'd:/tensor/cifar10/train100/4.png', 'd:/tensor/cifar10/train100/5.png', 'd:/tensor/cifar10/train100/6.png', 'd:/tensor/cifar10/train100/7.png', 'd:/tensor/cifar10/train100/8.png', 'd:/tensor/cifar10/train100/9.png', 'd:/tensor/cifar10/train100/10.png', 'd:/tensor/cifar10/train100/11.png', 'd:/tensor/cifar10/train100/12.png', 'd:/tensor/cifar10/train100/13.png', 'd:/tensor/cifar10/train100/14.png', 'd:/tensor/cifar10/train100/15.png', 'd:/tensor/cifar10/train100/16.png', 'd:/tensor/cifar10/train100/17.png', 'd:/tensor/cifar10/train100/18.png', 'd:/tensor/cifar10/train100/19.png', 'd:/tensor/cifar10/train100/20.png', 'd:/tensor/cifar10/train100/21.png', 'd:/tensor/cifar10/train100/22.png', 'd:/tensor/cifar10/train100/23.png', 'd:/tensor/cifar10/train100/24.png', 'd:/tensor/cifar10/train100/25.png', 'd:/tensor/cifar10/train100/26.png', 'd:/tensor/cifar10/train100/27.png', 'd:/tensor/cifar10/train100/28.png', 'd:/tensor/cifar10/train100/29.png', 'd:/tensor/cifar10/train100/30.png', 'd:/tensor/cifar10/train100/31.png', 'd:/tensor/cifar10/train100/32.png', 'd:/tensor/cifar10/train100/33.png', 'd:/tensor/cifar10/train100/34.png', 'd:/tensor/cifar10/train100/35.png', 'd:/tensor/cifar10/train100/36.png', 'd:/tensor/cifar10/train100/37.png', 'd:/tensor/cifar10/train100/38.png', 'd:/tensor/cifar10/train100/39.png', 'd:/tensor/cifar10/train100/40.png', 'd:/tensor/cifar10/train100/41.png', 'd:/tensor/cifar10/train100/42.png', 'd:/tensor/cifar10/train100/43.png', 'd:/tensor/cifar10/train100/44.png', 'd:/tensor/cifar10/train100/45.png', 'd:/tensor/cifar10/train100/46.png', 'd:/tensor/cifar10/train100/47.png', 'd:/tensor/cifar10/train100/48.png', 'd:/tensor/cifar10/train100/49.png', 'd:/tensor/cifar10/train100/50.png', 'd:/tensor/cifar10/train100/51.png', 'd:/tensor/cifar10/train100/52.png', 'd:/tensor/cifar10/train100/53.png', 'd:/tensor/cifar10/train100/54.png', 'd:/tensor/cifar10/train100/55.png', 'd:/tensor/cifar10/train100/56.png', 'd:/tensor/cifar10/train100/57.png', 'd:/tensor/cifar10/train100/58.png', 'd:/tensor/cifar10/train100/59.png', 'd:/tensor/cifar10/train100/60.png', 'd:/tensor/cifar10/train100/61.png', 'd:/tensor/cifar10/train100/62.png', 'd:/tensor/cifar10/train100/63.png', 'd:/tensor/cifar10/train100/64.png', 'd:/tensor/cifar10/train100/65.png', 'd:/tensor/cifar10/train100/66.png', 'd:/tensor/cifar10/train100/67.png', 'd:/tensor/cifar10/train100/68.png', 'd:/tensor/cifar10/train100/69.png', 'd:/tensor/cifar10/train100/70.png', 'd:/tensor/cifar10/train100/71.png', 'd:/tensor/cifar10/train100/72.png', 'd:/tensor/cifar10/train100/73.png', 'd:/tensor/cifar10/train100/74.png', 'd:/tensor/cifar10/train100/75.png', 'd:/tensor/cifar10/train100/76.png', 'd:/tensor/cifar10/train100/77.png', 'd:/tensor/cifar10/train100/78.png', 'd:/tensor/cifar10/train100/79.png', 'd:/tensor/cifar10/train100/80.png', 'd:/tensor/cifar10/train100/81.png', 'd:/tensor/cifar10/train100/82.png', 'd:/tensor/cifar10/train100/83.png', 'd:/tensor/cifar10/train100/84.png', 'd:/tensor/cifar10/train100/85.png', 'd:/tensor/cifar10/train100/86.png', 'd:/tensor/cifar10/train100/87.png', 'd:/tensor/cifar10/train100/88.png', 'd:/tensor/cifar10/train100/89.png', 'd:/tensor/cifar10/train100/90.png', 'd:/tensor/cifar10/train100/91.png', 'd:/tensor/cifar10/train100/92.png', 'd:/tensor/cifar10/train100/93.png', 'd:/tensor/cifar10/train100/94.png', 'd:/tensor/cifar10/train100/95.png', 'd:/tensor/cifar10/train100/96.png', 'd:/tensor/cifar10/train100/97.png', 'd:/tensor/cifar10/train100/98.png', 'd:/tensor/cifar10/train100/99.png', 'd:/tensor/cifar10/train100/100.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "def image_load(path):\n",
    "    file_list = os.listdir(path)\n",
    "\n",
    "    file_name = []\n",
    "    for i in file_list:\n",
    "        file_name.append(int(re.sub('[^0-9]', '', i)))\n",
    "\n",
    "    file_name.sort()\n",
    "\n",
    "    file_res = []\n",
    "    for i in file_name:\n",
    "        file_res.append(path+str(i)+'.png')\n",
    "\n",
    "    return file_res\n",
    "\n",
    "\n",
    "train_image = 'd:/tensor/cifar10/train100/'\n",
    "print(image_load(train_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제6. cv2.imread 함수를 이용해서 이미지를 숫자로 변경하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:02:37.721168Z",
     "start_time": "2020-08-18T07:02:34.558376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 63  62  59]\n",
      "   [ 45  46  43]\n",
      "   [ 43  48  50]\n",
      "   ...\n",
      "   [108 132 158]\n",
      "   [102 125 152]\n",
      "   [103 124 148]]\n",
      "\n",
      "  [[ 20  20  16]\n",
      "   [  0   0   0]\n",
      "   [  0   8  18]\n",
      "   ...\n",
      "   [ 55  88 123]\n",
      "   [ 50  83 119]\n",
      "   [ 57  87 122]]\n",
      "\n",
      "  [[ 21  24  25]\n",
      "   [  0   7  16]\n",
      "   [  8  27  49]\n",
      "   ...\n",
      "   [ 50  84 118]\n",
      "   [ 50  84 120]\n",
      "   [ 42  73 109]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 96 170 208]\n",
      "   [ 34 153 201]\n",
      "   [ 26 161 198]\n",
      "   ...\n",
      "   [ 70 133 160]\n",
      "   [  7  31  56]\n",
      "   [ 20  34  53]]\n",
      "\n",
      "  [[ 96 139 180]\n",
      "   [ 42 123 173]\n",
      "   [ 30 144 186]\n",
      "   ...\n",
      "   [ 94 148 184]\n",
      "   [ 34  62  97]\n",
      "   [ 34  53  83]]\n",
      "\n",
      "  [[116 144 177]\n",
      "   [ 94 129 168]\n",
      "   [ 87 142 179]\n",
      "   ...\n",
      "   [140 184 216]\n",
      "   [ 84 118 151]\n",
      "   [ 72  92 123]]]\n",
      "\n",
      "\n",
      " [[[187 177 154]\n",
      "   [136 137 126]\n",
      "   [ 95 104 105]\n",
      "   ...\n",
      "   [ 71  95  91]\n",
      "   [ 71  90  87]\n",
      "   [ 70  81  79]]\n",
      "\n",
      "  [[169 160 140]\n",
      "   [154 153 145]\n",
      "   [118 125 125]\n",
      "   ...\n",
      "   [ 78  99  96]\n",
      "   [ 62  80  77]\n",
      "   [ 61  73  71]]\n",
      "\n",
      "  [[164 155 140]\n",
      "   [149 146 139]\n",
      "   [112 115 115]\n",
      "   ...\n",
      "   [ 64  82  79]\n",
      "   [ 55  70  68]\n",
      "   [ 55  69  67]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[166 167 175]\n",
      "   [160 154 156]\n",
      "   [170 160 154]\n",
      "   ...\n",
      "   [ 36  34  42]\n",
      "   [ 57  53  61]\n",
      "   [ 91  83  93]]\n",
      "\n",
      "  [[128 154 165]\n",
      "   [130 152 156]\n",
      "   [142 161 159]\n",
      "   ...\n",
      "   [ 96  93 103]\n",
      "   [120 114 123]\n",
      "   [131 121 131]]\n",
      "\n",
      "  [[120 148 163]\n",
      "   [122 148 158]\n",
      "   [133 156 163]\n",
      "   ...\n",
      "   [139 133 143]\n",
      "   [142 134 143]\n",
      "   [144 133 143]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [253 253 253]\n",
      "   [253 253 253]\n",
      "   ...\n",
      "   [253 253 253]\n",
      "   [253 253 253]\n",
      "   [253 253 253]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [254 254 254]\n",
      "   [254 254 254]\n",
      "   ...\n",
      "   [254 254 254]\n",
      "   [254 254 254]\n",
      "   [254 254 254]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[112 120 113]\n",
      "   [111 118 111]\n",
      "   [106 112 105]\n",
      "   ...\n",
      "   [ 80  81  72]\n",
      "   [ 79  80  72]\n",
      "   [ 79  80  72]]\n",
      "\n",
      "  [[110 118 111]\n",
      "   [104 111 104]\n",
      "   [ 98 106  99]\n",
      "   ...\n",
      "   [ 73  75  68]\n",
      "   [ 75  76  70]\n",
      "   [ 82  84  78]]\n",
      "\n",
      "  [[105 113 106]\n",
      "   [ 98 106  99]\n",
      "   [ 94 102  95]\n",
      "   ...\n",
      "   [ 83  85  78]\n",
      "   [ 83  85  79]\n",
      "   [ 84  86  80]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 27  44  33]\n",
      "   [ 31  44  29]\n",
      "   [ 34  45  32]\n",
      "   ...\n",
      "   [221 197 157]\n",
      "   [216 199 162]\n",
      "   [213 194 160]]\n",
      "\n",
      "  [[ 24  40  25]\n",
      "   [ 27  40  24]\n",
      "   [ 29  36  23]\n",
      "   ...\n",
      "   [227 209 174]\n",
      "   [217 199 167]\n",
      "   [220 198 165]]\n",
      "\n",
      "  [[ 47  56  55]\n",
      "   [ 46  56  47]\n",
      "   [ 52  61  53]\n",
      "   ...\n",
      "   [165 162 129]\n",
      "   [133 137 110]\n",
      "   [154 153 123]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 60  97 106]\n",
      "   [ 58  91 103]\n",
      "   [ 53 100  85]\n",
      "   ...\n",
      "   [ 52  91  78]\n",
      "   [ 36  64  54]\n",
      "   [ 31  56  44]]\n",
      "\n",
      "  [[ 59  91  97]\n",
      "   [ 57  97  92]\n",
      "   [ 61 108  88]\n",
      "   ...\n",
      "   [ 59 107  96]\n",
      "   [ 47  94  81]\n",
      "   [ 41  88  71]]\n",
      "\n",
      "  [[ 91 119 106]\n",
      "   [115 141 128]\n",
      "   [137 158 142]\n",
      "   ...\n",
      "   [ 63 108 100]\n",
      "   [ 47  94  81]\n",
      "   [ 40  90  71]]]\n",
      "\n",
      "\n",
      " [[[ 59  77  90]\n",
      "   [ 64  81  94]\n",
      "   [ 65  81  87]\n",
      "   ...\n",
      "   [ 35  44  46]\n",
      "   [ 38  45  53]\n",
      "   [ 38  46  57]]\n",
      "\n",
      "  [[ 68  92  96]\n",
      "   [ 63  84 101]\n",
      "   [ 66  80  95]\n",
      "   ...\n",
      "   [ 44  51  60]\n",
      "   [ 50  60  72]\n",
      "   [ 45  56  71]]\n",
      "\n",
      "  [[ 66  87  85]\n",
      "   [ 75 102 113]\n",
      "   [ 76 101 115]\n",
      "   ...\n",
      "   [ 57  84  90]\n",
      "   [ 60  87  96]\n",
      "   [ 55  79  91]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 88 105 102]\n",
      "   [ 47  69  61]\n",
      "   [ 53  74  69]\n",
      "   ...\n",
      "   [ 95 142 157]\n",
      "   [ 94 137 152]\n",
      "   [ 95 152 169]]\n",
      "\n",
      "  [[ 69  96 101]\n",
      "   [ 52  66  69]\n",
      "   [ 53  68  64]\n",
      "   ...\n",
      "   [100 125 131]\n",
      "   [ 91 117 123]\n",
      "   [ 79 109 115]]\n",
      "\n",
      "  [[ 61  86  91]\n",
      "   [ 58  72  78]\n",
      "   [ 68  86  87]\n",
      "   ...\n",
      "   [ 85 126 135]\n",
      "   [ 81 116 120]\n",
      "   [ 80  96 102]]]\n",
      "\n",
      "\n",
      " [[[ 44  64  62]\n",
      "   [ 26  50  50]\n",
      "   [ 19  44  46]\n",
      "   ...\n",
      "   [ 69 172 167]\n",
      "   [ 76 184 183]\n",
      "   [ 72 136 137]]\n",
      "\n",
      "  [[ 37  65  63]\n",
      "   [ 26  53  55]\n",
      "   [ 27  50  52]\n",
      "   ...\n",
      "   [ 61 169 163]\n",
      "   [ 75 174 171]\n",
      "   [ 77 146 145]]\n",
      "\n",
      "  [[ 36  62  58]\n",
      "   [ 37  66  64]\n",
      "   [ 37  60  56]\n",
      "   ...\n",
      "   [ 62 155 153]\n",
      "   [ 64 154 150]\n",
      "   [ 57 128 123]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 99 135 172]\n",
      "   [ 84 110 143]\n",
      "   [ 42  56 130]\n",
      "   ...\n",
      "   [ 56  75  94]\n",
      "   [ 86 108 141]\n",
      "   [ 81 105 139]]\n",
      "\n",
      "  [[117 146 183]\n",
      "   [ 95 118 150]\n",
      "   [ 44  64  80]\n",
      "   ...\n",
      "   [ 60  72  81]\n",
      "   [ 98 118 135]\n",
      "   [110 125 143]]\n",
      "\n",
      "  [[144 174 209]\n",
      "   [123 151 182]\n",
      "   [ 83 109 139]\n",
      "   ...\n",
      "   [ 47  54  59]\n",
      "   [111 119 130]\n",
      "   [160 156 169]]]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def image_load(path):\n",
    "    file_list = os.listdir(path)\n",
    "\n",
    "    file_name = []\n",
    "    for i in file_list:\n",
    "        file_name.append(int(re.sub('[^0-9]', '', i)))\n",
    "\n",
    "    file_name.sort()\n",
    "\n",
    "    file_res = []\n",
    "    for j in file_name:\n",
    "        file_res.append(path+str(j)+'.png')\n",
    "        \n",
    "    image = []\n",
    "    for k in file_res:\n",
    "        image.append(cv2.imread(k))\n",
    "\n",
    "    return np.array(image)\n",
    "\n",
    "\n",
    "train_image = 'd:/tensor/cifar10/train100/'\n",
    "print(image_load(train_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>■ 데이터를 신경망에 로드하기 위해 필요한 총 4개의 함수</b>\n",
    "    1. image_load : 데이터를 숫자로 변환하는 함수\n",
    "    2. label_load : 정답 숫자를 one hot encoding하는 함수\n",
    "    3. next_batch : 배치 단위로 데이터 가져오는 함수\n",
    "    4. shuffle_batch : 이미지 데이터를 shuffle 하는 함수    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제8. train_label.csv의 숫자를 출력하는 함수를 만드시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:25:11.810546Z",
     "start_time": "2020-08-18T07:25:11.616666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "train_label = 'd:/tensor/cifar10/train_label.csv'\n",
    "\n",
    "import csv\n",
    "\n",
    "def label_load(path):\n",
    "    file = open(path)    \n",
    "    label_data = csv.reader(file)\n",
    "    \n",
    "    label_list = []    \n",
    "    for i in label_data:\n",
    "        label_list.append(i)\n",
    "        \n",
    "    return label_list\n",
    "print(label_load(train_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제9. 위의 결과가 문자가 아니라 숫자로 출력되게 하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:28:33.357979Z",
     "start_time": "2020-08-18T07:28:33.281026Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6]\n",
      " [9]\n",
      " [9]\n",
      " ...\n",
      " [9]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "train_label = 'd:/tensor/cifar10/train_label.csv'\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def label_load(path):\n",
    "    file = open(path)    \n",
    "    label_data = csv.reader(file)\n",
    "    \n",
    "    label_list = []    \n",
    "    for i in label_data:\n",
    "        label_list.append(i)\n",
    "    \n",
    "    label = np.array(label_list).astype(int)\n",
    "        \n",
    "    return label\n",
    "print(label_load(train_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제10. 아래의 결과를 출력하시오\n",
    "    [0 0 0 1 0 0 0 0 0 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:31:36.675433Z",
     "start_time": "2020-08-18T07:31:36.670434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.eye(10)[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제11. 위의 np.eye를 가지고 예제 9에서 출력하고 있는 숫자들이 아래와 같이 one hot encoding된 숫자로 출력되게 하시오\n",
    "    [0 0 0 1 0 0 0 0 0 0]\n",
    "    [0 0 1 0 0 0 0 0 0 0]\n",
    "    [1 0 0 0 0 0 0 0 0 0]\n",
    "    [0 0 0 0 0 0 0 1 0 0]\n",
    "            ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:35:04.141082Z",
     "start_time": "2020-08-18T07:35:03.928203Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 1.]]\n",
      "\n",
      " [[0. 1. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "train_label = 'd:/tensor/cifar10/train_label.csv'\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def label_load(path):\n",
    "    file = open(path)    \n",
    "    label_data = csv.reader(file)\n",
    "    \n",
    "    label_list = []    \n",
    "    for i in label_data:\n",
    "        label_list.append(i)\n",
    "    \n",
    "    label = np.eye(10)[np.array(label_list).astype(int)]\n",
    "    \n",
    "    return label\n",
    "\n",
    "print(label_load(train_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제12. 위의 결과는 3차원인데 신경망에서 라벨을 사용하려면 2차원이어야 하므로 차원을 2차원으로 축소시켜서 출력하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:38:18.714312Z",
     "start_time": "2020-08-18T07:38:18.647352Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "train_label = 'd:/tensor/cifar10/train_label.csv'\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def label_load(path):\n",
    "    file = open(path)    \n",
    "    label_data = csv.reader(file)\n",
    "    \n",
    "    label_list = []    \n",
    "    for i in label_data:\n",
    "        label_list.append(i)\n",
    "    \n",
    "    label = np.eye(10)[np.array(label_list).astype(int)].reshape(-1,10)\n",
    "    \n",
    "    return label\n",
    "\n",
    "print(label_load(train_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제13. 지금까지 만든 두 개의 함수 image_load와 label_load를 loader2.py라는 파이썬 코드에 저장하고 아래와 같이 loader2.py를 import한 후에 cifar10 전체 데이터를 로드하는 코드를 구현하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:48:28.350673Z",
     "start_time": "2020-08-18T07:46:43.995369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import loader2\n",
    "\n",
    "train_image='D:/tensor/cifar10/train/'\n",
    "train_label = 'D:/tensor/cifar10/train_label.csv'\n",
    "test_image='D:/tensor/cifar10/test/'\n",
    "test_label = 'D:/tensor/cifar10/test_label.csv'\n",
    "\n",
    "\n",
    "trainX = loader2.image_load(train_image)\n",
    "trainY = loader2.label_load(train_label)\n",
    "testX = loader2.image_load(test_image)\n",
    "testY = loader2.label_load(test_label)\n",
    "\n",
    "print ( trainX.shape)\n",
    "print ( trainY.shape)\n",
    "print ( testX.shape)\n",
    "print ( testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제14. 신경망에 100장씩 데이터를 로드할 수 있도록 아래와 같이 next_batch 함수를 생성하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:55:07.363179Z",
     "start_time": "2020-08-18T07:53:29.899492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[[ 49, 112, 158],\n",
      "         [ 47, 111, 159],\n",
      "         [ 51, 116, 165],\n",
      "         ...,\n",
      "         [ 36,  95, 137],\n",
      "         [ 36,  91, 126],\n",
      "         [ 33,  85, 116]],\n",
      "\n",
      "        [[ 51, 112, 152],\n",
      "         [ 40, 110, 151],\n",
      "         [ 45, 114, 159],\n",
      "         ...,\n",
      "         [ 31,  95, 136],\n",
      "         [ 32,  91, 125],\n",
      "         [ 34,  88, 119]],\n",
      "\n",
      "        [[ 47, 110, 151],\n",
      "         [ 33, 109, 151],\n",
      "         [ 36, 111, 158],\n",
      "         ...,\n",
      "         [ 34,  98, 139],\n",
      "         [ 34,  95, 130],\n",
      "         [ 33,  89, 120]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[177, 124,  68],\n",
      "         [148, 100,  42],\n",
      "         [137,  88,  31],\n",
      "         ...,\n",
      "         [146,  97,  38],\n",
      "         [108,  64,  13],\n",
      "         [127,  85,  40]],\n",
      "\n",
      "        [[168, 116,  61],\n",
      "         [148, 102,  49],\n",
      "         [132,  85,  35],\n",
      "         ...,\n",
      "         [130,  82,  26],\n",
      "         [126,  82,  29],\n",
      "         [107,  64,  20]],\n",
      "\n",
      "        [[160, 107,  54],\n",
      "         [149, 105,  56],\n",
      "         [132,  89,  45],\n",
      "         ...,\n",
      "         [124,  77,  24],\n",
      "         [129,  84,  34],\n",
      "         [110,  67,  21]]],\n",
      "\n",
      "\n",
      "       [[[235, 235, 235],\n",
      "         [231, 231, 231],\n",
      "         [232, 232, 232],\n",
      "         ...,\n",
      "         [233, 233, 233],\n",
      "         [233, 233, 233],\n",
      "         [232, 232, 232]],\n",
      "\n",
      "        [[238, 238, 238],\n",
      "         [235, 235, 235],\n",
      "         [235, 235, 235],\n",
      "         ...,\n",
      "         [236, 236, 236],\n",
      "         [236, 236, 236],\n",
      "         [235, 235, 235]],\n",
      "\n",
      "        [[237, 237, 237],\n",
      "         [234, 234, 234],\n",
      "         [234, 234, 234],\n",
      "         ...,\n",
      "         [235, 235, 235],\n",
      "         [235, 235, 235],\n",
      "         [234, 234, 234]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 89,  99,  87],\n",
      "         [ 37,  51,  43],\n",
      "         [ 11,  23,  19],\n",
      "         ...,\n",
      "         [179, 184, 169],\n",
      "         [193, 197, 182],\n",
      "         [201, 202, 188]],\n",
      "\n",
      "        [[ 82,  96,  82],\n",
      "         [ 36,  57,  46],\n",
      "         [ 22,  44,  36],\n",
      "         ...,\n",
      "         [183, 189, 174],\n",
      "         [196, 200, 185],\n",
      "         [200, 202, 187]],\n",
      "\n",
      "        [[ 83, 101,  85],\n",
      "         [ 48,  75,  62],\n",
      "         [ 38,  67,  58],\n",
      "         ...,\n",
      "         [178, 183, 168],\n",
      "         [191, 195, 180],\n",
      "         [199, 200, 186]]],\n",
      "\n",
      "\n",
      "       [[[222, 190, 158],\n",
      "         [218, 187, 158],\n",
      "         [194, 166, 139],\n",
      "         ...,\n",
      "         [234, 231, 228],\n",
      "         [243, 239, 237],\n",
      "         [246, 241, 238]],\n",
      "\n",
      "        [[229, 200, 170],\n",
      "         [226, 199, 172],\n",
      "         [201, 176, 151],\n",
      "         ...,\n",
      "         [236, 232, 232],\n",
      "         [250, 246, 246],\n",
      "         [251, 247, 246]],\n",
      "\n",
      "        [[225, 201, 174],\n",
      "         [222, 200, 176],\n",
      "         [199, 179, 157],\n",
      "         ...,\n",
      "         [232, 229, 230],\n",
      "         [251, 249, 250],\n",
      "         [247, 244, 245]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 45,  40,  31],\n",
      "         [ 44,  39,  30],\n",
      "         [ 40,  35,  26],\n",
      "         ...,\n",
      "         [ 46,  40,  37],\n",
      "         [ 14,  13,   9],\n",
      "         [  5,   7,   4]],\n",
      "\n",
      "        [[ 39,  34,  23],\n",
      "         [ 43,  38,  27],\n",
      "         [ 41,  36,  25],\n",
      "         ...,\n",
      "         [ 24,  20,  19],\n",
      "         [  3,   6,   4],\n",
      "         [  3,   7,   5]],\n",
      "\n",
      "        [[ 47,  41,  28],\n",
      "         [ 50,  43,  30],\n",
      "         [ 52,  45,  32],\n",
      "         ...,\n",
      "         [  8,   6,   5],\n",
      "         [  3,   5,   4],\n",
      "         [  7,   8,   7]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[149, 135, 132],\n",
      "         [150, 137, 133],\n",
      "         [151, 139, 135],\n",
      "         ...,\n",
      "         [151, 138, 130],\n",
      "         [152, 137, 130],\n",
      "         [152, 137, 130]],\n",
      "\n",
      "        [[152, 140, 138],\n",
      "         [153, 141, 139],\n",
      "         [153, 141, 139],\n",
      "         ...,\n",
      "         [153, 140, 133],\n",
      "         [153, 139, 132],\n",
      "         [153, 138, 131]],\n",
      "\n",
      "        [[151, 140, 139],\n",
      "         [151, 140, 139],\n",
      "         [153, 141, 141],\n",
      "         ...,\n",
      "         [151, 139, 132],\n",
      "         [151, 138, 131],\n",
      "         [151, 137, 131]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 17,  38,  23],\n",
      "         [ 10,  33,  19],\n",
      "         [ 18,  38,  25],\n",
      "         ...,\n",
      "         [145, 137, 135],\n",
      "         [145, 138, 135],\n",
      "         [145, 137, 135]],\n",
      "\n",
      "        [[ 13,  30,  17],\n",
      "         [ 11,  26,  14],\n",
      "         [ 12,  30,  17],\n",
      "         ...,\n",
      "         [146, 138, 137],\n",
      "         [146, 138, 137],\n",
      "         [146, 138, 137]],\n",
      "\n",
      "        [[  8,  24,  13],\n",
      "         [ 10,  24,  13],\n",
      "         [ 10,  25,  14],\n",
      "         ...,\n",
      "         [144, 136, 134],\n",
      "         [143, 136, 134],\n",
      "         [143, 136, 134]]],\n",
      "\n",
      "\n",
      "       [[[255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         ...,\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255]],\n",
      "\n",
      "        [[255, 255, 255],\n",
      "         [254, 254, 254],\n",
      "         [254, 254, 254],\n",
      "         ...,\n",
      "         [254, 254, 254],\n",
      "         [254, 254, 254],\n",
      "         [254, 254, 254]],\n",
      "\n",
      "        [[255, 255, 255],\n",
      "         [254, 254, 254],\n",
      "         [255, 255, 255],\n",
      "         ...,\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[255, 255, 255],\n",
      "         [254, 254, 254],\n",
      "         [255, 255, 255],\n",
      "         ...,\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255]],\n",
      "\n",
      "        [[255, 255, 255],\n",
      "         [254, 254, 254],\n",
      "         [255, 255, 255],\n",
      "         ...,\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255]],\n",
      "\n",
      "        [[255, 255, 255],\n",
      "         [254, 254, 254],\n",
      "         [255, 255, 255],\n",
      "         ...,\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255]]],\n",
      "\n",
      "\n",
      "       [[[238, 233, 234],\n",
      "         [241, 237, 238],\n",
      "         [242, 238, 239],\n",
      "         ...,\n",
      "         [247, 244, 246],\n",
      "         [249, 246, 248],\n",
      "         [251, 248, 249]],\n",
      "\n",
      "        [[233, 228, 229],\n",
      "         [236, 231, 232],\n",
      "         [237, 232, 233],\n",
      "         ...,\n",
      "         [245, 242, 244],\n",
      "         [247, 244, 246],\n",
      "         [248, 246, 248]],\n",
      "\n",
      "        [[236, 230, 231],\n",
      "         [238, 232, 233],\n",
      "         [238, 232, 233],\n",
      "         ...,\n",
      "         [250, 248, 250],\n",
      "         [251, 249, 251],\n",
      "         [252, 251, 252]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 55,  75, 115],\n",
      "         [ 55,  72, 107],\n",
      "         [ 56,  71, 106],\n",
      "         ...,\n",
      "         [151, 198, 226],\n",
      "         [128, 176, 212],\n",
      "         [131, 181, 217]],\n",
      "\n",
      "        [[ 55,  74, 113],\n",
      "         [ 55,  70, 103],\n",
      "         [ 55,  69,  99],\n",
      "         ...,\n",
      "         [138, 191, 215],\n",
      "         [128, 182, 206],\n",
      "         [129, 177, 207]],\n",
      "\n",
      "        [[ 54,  71, 106],\n",
      "         [ 57,  72, 105],\n",
      "         [ 56,  72, 103],\n",
      "         ...,\n",
      "         [125, 178, 203],\n",
      "         [137, 193, 213],\n",
      "         [127, 178, 199]]]], dtype=uint8), array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]))\n"
     ]
    }
   ],
   "source": [
    "import loader2\n",
    "\n",
    "def next_batch(data1, data2, init, final):\n",
    "    return data1[init:final], data2[init:final]\n",
    "\n",
    "test_image = 'D:/tensor/cifar10/test/'\n",
    "test_label = 'D:/tensor/cifar10/test_label.csv'\n",
    "\n",
    "testX = loader2.image_load(test_image)\n",
    "testY = loader2.label_load(test_label)\n",
    "\n",
    "print(next_batch(testX, testY, 0 ,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제15. 아래와 같이 shuffle_batch 함수를 만들고 loader2.py에 추가시키시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:58:25.395557Z",
     "start_time": "2020-08-18T07:58:25.390560Z"
    }
   },
   "outputs": [],
   "source": [
    "def shuffle_batch(data_list, label):\n",
    "    x = np.arange(len(data_list))\n",
    "    np.random.shuffle(x)\n",
    "    \n",
    "    data_list2 = data_list[x]\n",
    "    label2 = label[x]\n",
    "    \n",
    "    return data_list2, label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:01:53.128542Z",
     "start_time": "2020-08-18T08:01:49.511773Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'loader2' has no attribute 'shuffle_batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-06c8c0c96bfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtestY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloader2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'loader2' has no attribute 'shuffle_batch'"
     ]
    }
   ],
   "source": [
    "import loader2\n",
    "\n",
    "test_image = 'D:/tensor/cifar10/test/'\n",
    "test_label = 'D:/tensor/cifar10/test_label.csv'\n",
    "\n",
    "testX = loader2.image_load(test_image)\n",
    "testY = loader2.label_load(test_label)\n",
    "\n",
    "print(loader2.shuffle_batch(testX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※ 문제141. (오늘의 마지막 문제) 4개의 함수를 모두 loader2.py에 넣고 내일 옥스포드에서 설계한 vgg 신경망에 넣기 위해 아래와 같이 실행되게 하시오\n",
    "```python\n",
    "import loader2\n",
    "\n",
    "train_image='D:/tensor/cifar10/train/'\n",
    "train_label = 'D:/tensor/cifar10/train_label.csv'\n",
    "test_image='D:/tensor/cifar10/test/'\n",
    "test_label = 'D:/tensor/cifar10/test_label.csv'\n",
    "\n",
    "\n",
    "trainX = loader2.image_load(train_image)\n",
    "trainY = loader2.label_load(train_label)\n",
    "testX = loader2.image_load(test_image)\n",
    "testY = loader2.label_load(test_label)\n",
    "\n",
    "testX, testY = loader2.shuffle_batch(testX, testY)\n",
    "print(loader2.next_batch(testX, testY, 0, 100))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:10:15.702441Z",
     "start_time": "2020-08-18T08:05:55.222178Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'loader2' has no attribute 'shuffle_batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-e082237ac53a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mtestY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloader2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloader2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'loader2' has no attribute 'shuffle_batch'"
     ]
    }
   ],
   "source": [
    "import loader2\n",
    "\n",
    "train_image='D:/tensor/cifar10/train/'\n",
    "train_label = 'D:/tensor/cifar10/train_label.csv'\n",
    "test_image='D:/tensor/cifar10/test/'\n",
    "test_label = 'D:/tensor/cifar10/test_label.csv'\n",
    "\n",
    "\n",
    "trainX = loader2.image_load(train_image)\n",
    "trainY = loader2.label_load(train_label)\n",
    "testX = loader2.image_load(test_image)\n",
    "testY = loader2.label_load(test_label)\n",
    "\n",
    "testX, testY = loader2.shuffle_batch(testX, testY)\n",
    "print(loader2.next_batch(testX, testY, 0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>■ 훈련시킨 가중치와 바이어스를 pickle 파일로 내리는 코드</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
